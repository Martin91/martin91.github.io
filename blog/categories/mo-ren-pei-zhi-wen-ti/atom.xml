<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 默认配置问题 | Martin]]></title>
  <link href="http://Martin91.github.io/blog/categories/mo-ren-pei-zhi-wen-ti/atom.xml" rel="self"/>
  <link href="http://Martin91.github.io/"/>
  <updated>2018-02-10T21:57:53+08:00</updated>
  <id>http://Martin91.github.io/</id>
  <author>
    <name><![CDATA[Martin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[记一次Redis数据库配置导致的连接数泄露的问题]]></title>
    <link href="http://Martin91.github.io/blog/articles/2018/02/10/ji-yi-ci-redisshu-ju-ku-pei-zhi-dao-zhi-de-lian-jie-shu-xie-lou-de-wen-ti/"/>
    <updated>2018-02-10T20:35:39+08:00</updated>
    <id>http://Martin91.github.io/blog/articles/2018/02/10/ji-yi-ci-redisshu-ju-ku-pei-zhi-dao-zhi-de-lian-jie-shu-xie-lou-de-wen-ti</id>
    <content type="html"><![CDATA[<h3>问题背景</h3>

<p>去年圣诞节当天，突然收到一个我经手过的项目的告警邮件，错误消息显示<strong>“Redis::CommandError: ERR max number of clients reached”</strong>。
<img src="/images/posts/20180210/redis%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.002.jpeg" alt="Redis 连接数告警" /></p>

<p>什么情况？难道这个项目翻车了？第一反应是这台服务器运行着自建的 Redis 数据库，但是客户端只有同个内网的一个 Ruby on Rails 的应用，怎么会有连接数爆掉的可能？</p>

<!-- MORE -->


<h4>理论连接数计算</h4>

<p>老衲掐指一算：</p>

<ol>
<li><strong>sidekiq 客户端所需连接数</strong>: 对面 Rails 应用有 10 个 Unicorn 工作进程，每个unicorn进程初始化一个 sidekiq 客户端，一个 sidekiq 客户端默认连接池大小是 5，而且是懒惰策略，按需连接的，最大值是 10 x 5 = 50；</li>
<li><strong>显式 Redis 连接</strong>: 程序代码里有一个 $redis 全局变量，初始化了一个 redis 连接，10个工作进程，也就是 10 个连接；</li>
<li><strong>sidekiq 服务端所需连接数</strong>: sidekiq server 端 concurrency 配置是 10，那么按照官方文档，另有加上 2 个连接，也就是12个连接；</li>
<li><strong>Rails cache 所需连接数</strong>: 按照<code>redis-store</code> gem 源码，默认连接池大小应该是 5，10个 unicorn 工作进程，按需连接，最大值是 10 x 5 = 50。</li>
</ol>


<p>在不考虑其他可能还用到 Redis 连接的情况下，目前已知的最大 Redis 连接数需求是 122，这个数远小于 Redis 理论最大连接数啊，而且当时显示连接数到达上万！而且这个项目已经很少访问，压力极其小，不大可能会达到理论所需连接数啊！</p>

<p>一定是有<strong>某种神秘力量</strong>在主导这一切！！！</p>

<h3>监控与分析</h3>

<p>以上理论最大连接数分析只是定性分析，只能大概说明有一些诡异的东西存在，而想真正确认问题根源，还得做定量分析，只有数据才能说明一切！</p>

<h4>初步观察：Redis 数据库服务器端监控</h4>

<p>事不宜迟，要采集数据，第一步就是加监控，所以当时就紧急写了一个定时采集 Redis 客户端数量（使用 redis 内建 <code>CLIENT LIST</code> 命令）的脚本，结合 crontab 定时运行，将结果写入文件，作为后续分析的基础。
<img src="/images/posts/20180210/redis%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.003.jpg" alt="监控脚本" /></p>

<p>通过监控脚本，发现几个有意思的现象：</p>

<ol>
<li>从 Redis 数据库服务端采集的数据看，<strong>一直只有来自一台内网机器，也就是我前面说的 Rails 程序所在的服务器的连接</strong>，说明这个 Redis 数据库不存在共享给其他应用的可能性；</li>
<li>经过3天左右的监控，即从12.25到12.28，连续3天，Redis 连接数一直稳步上升，平均每日增加 70-80。在典型的系统资源泄露类（比如内存泄露）问题的场景中，这样的线条看起来特别熟悉，所以，真的是<strong>连接数泄露</strong>了？
<img src="/images/posts/20180210/redis%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.004.jpeg" alt="连接数数量稳步攀升" /></li>
</ol>


<h4>进一步分析：Redis 数据库服务器端与客户端连接数对比分析</h4>

<p>在有了上一步的发现之后，我继续用系统命令 <code>sudo netstat -apnt</code> 检查 <code>6379</code> 端口连接数发现，客户端机器也才只有 42 个左右的连接到 redis 服务器端，结合最开始的理论连接数分析，这个数量是比较合理的。</p>

<p>但是！但是！反过来去服务端机器用同样的命令检查，在服务端视角，却有多达300+个客户端建立的连接，而且都是在 ESTABLISHED 状态！这个数量和上面另一种监控方式得到的数量一致！
<img src="/images/posts/20180210/redis%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.005.jpeg" alt="服务器端与客户端 TCP 连接数不匹配" /></p>

<p>到底是什么情况？还能有这种操作？
<img src="/images/posts/20180210/redis%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.006.jpeg" alt="服务器端与客户端谁真谁假" /></p>

<h3>问题根源</h3>

<p>至此，Redis 连接数泄露是板上钉钉的事情了，可是又是为什么呢？为此，我在网上搜索了很多问答跟文章，后来总算找到了答案，果不其然，还是默认配置的问题。</p>

<h4>Redis 默认配置</h4>

<blockquote><p>redis 为了避免客户端连接数过多，有一个timeout配置，意思是如果连接的空闲时间超过了timeout的值，则关闭连接。默认配置是0，意思是没有超时限制，永远不关闭连接。生产上显然不会配置0……
<img src="/images/posts/20180210/redis%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.007.jpeg" alt="redis timeout配置解释" /></p></blockquote>

<p>OMG！赶紧打开我们的 redis 的配置文件验证是否如此，果不其然，redis一直保持着默认配置！
<img src="/images/posts/20180210/redis%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.008.jpeg" alt="redis timeout 默认配置" /></p>

<p>至此，很好解释为什么连接数会泄露了，因为有很多空闲或者实际上客户端已经断开的连接，在服务器端一侧仍然保持着。那什么情况会导致这样的情况发生呢？</p>

<p>我猜测：</p>

<ol>
<li><strong>网络通信差</strong>: 按照 TCP 协议，客户端断开连接时，向服务器端发送 FIN 信号，但是服务端未接收到，客户端超时后放弃等待，直接断开，服务端由于通信故障，保持了 ESTABLISHED 状态，不过由于两端机器在同个内网，网络质量没有理由不行；</li>
<li><strong>客户端异常</strong>: 客户端连接之后，由于代码运行过程中产生异常，导致未正常释放或者关闭连接，sidekiq 的worker很可能就有这类问题。这个的可能性非常大，毕竟我日常写 bug (<em>/ω╲</em>)。</li>
</ol>


<h3>问题修复</h3>

<p>找到问题根源之后，修复起来就简直太简单了。事实上，开发领域就是如此，绝大部分时间都花在了找 bug 上，而改掉bug，可能只需要一分钟不到。</p>

<p>首先，修改了下 redis 数据库配置：
<img src="/images/posts/20180210/redis%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.009.jpeg" alt="redis 修改成建议配置" /></p>

<p>成功重启 redis 之后，重新运行前面的监控脚本，以便观察修复后情况，初步可以确认这下服务器端和客户端的连接数一致了：</p>

<p><img src="/images/posts/20180210/redis%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.010.jpeg" alt="配置生效重启后，多次重新检查两端看到的连接数，都一直保持一致了，说明服务端能正常释放一些 idle 连接了。" /></p>

<p>再又经过几天的脚本自动采集数据后分析，系统又恢复平稳运行了，连接数一直稳定在理论最大连接数之下。
<img src="/images/posts/20180210/redis%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.011.jpeg" alt="redis 连接数稳定，稳定在理论最大连接数之下" /></p>

<h3>总结</h3>

<p>这个问题的根源其实很小，但是排查过程还是花了挺多时间，主要是需要等待采集到足够的数据后用于分析。其他心得体会：</p>

<ol>
<li>保护“案发现场”很重要，要想挖掘问题根源，必须保持环境可重现，这次出现问题的时候虽然第一时间重启了 redis 使服务恢复，但是由于没有修改任何配置，所以使得后来的监控能够发现问题根源；</li>
<li>使用开源软件，必须对默认配置保持警惕，相信应该有人以前听说过 redis 默认监听<code>0.0.0.0</code>来源请求的安全漏洞；</li>
<li>这个项目由于开始较早，当时并没有考虑使用 Redis 云数据库，自建数据库有风险，需要慎重对待，尽可能的情况下，专业的事情，交给专业的人去做。</li>
</ol>

]]></content>
  </entry>
  
</feed>
